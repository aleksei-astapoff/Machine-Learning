import pandas as pd
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score


data_path = './data/AER_credit_card_data.csv'
# Загрузка данных в Pandas DataFrame с помощью read_csv()
data = pd.read_csv(
    data_path,
    true_values=['yes'],
    false_values=['no']
)

# Определение целевой переменной
y = data.card

# Обучающая выборка
X = data.drop(['card'], axis=1)

print()
print("Number of rows in the dataset:", X.shape[0])
print()
print(X.head())
print()

# Поскольку нет предварительной обработки данных,
# создание конвейера не обязательно.
# Однако конвейер все равно используется как лучшая практика,
# так как это позволяет легко добавлять шаги предварительной обработки,
# если это потребуется в будущем.
my_pipeline = make_pipeline(RandomForestClassifier(n_estimators=100))

# Оценка модели с использованием кросс-валидации.
# cross_val_score автоматически разделяет данные
# на тренировочные и тестовые наборы (cv=5 означает 5 фолдов).
# my_pipeline — это конвейер с моделью случайного леса,
# который будет оцениваться.
# X и y — это входные данные и целевые метки соответственно.
# scoring='accuracy' указывает,
# что для оценки будет использоваться метрика точности (accuracy).
cv_scores = cross_val_score(
    my_pipeline, X, y,
    cv=5,  # Использование 5-кратной кросс-валидации
    scoring='accuracy')  # Метрика для оценки — точность

# Выводим среднюю точность, полученную в процессе кросс-валидации.
# cv_scores.mean() вычисляет среднее значение точности по всем 5 фолдам.
print("Cross-validation accuracy: %f" % cv_scores.mean())
print()

# Извлечение данных о расходах держателей карт.
# X.expenditure — это столбец "expenditure" (расходы) в наборе данных X.
# y — это булевый массив (или серия), где True означает,
# что клиент является держателем карты, а False — нет.
# Мы используем этот булевый массив для фильтрации строк
# в столбце "expenditure", относящихся только к держателям карт.
expenditures_cardholders = X.expenditure[y]

# Извлечение данных о расходах клиентов, не являющихся держателями карт.
# Здесь используется инверсия булевых значений с помощью оператора "~",
# чтобы выбрать строки, где y равно False.
# Таким образом, фильтруются строки в столбце "expenditure",
# относящиеся только к клиентам, не являющимся держателями карт.
expenditures_noncardholders = X.expenditure[~y]

# Выводим долю тех, кто не получил карту и не сделал никаких расходов.
# (expenditures_noncardholders == 0) — это булевый массив, где True для тех,
# у кого расходы равны 0.
# .mean() вычисляет среднее значение булевого массива,
# что эквивалентно доле True, то есть доле тех, у кого расходы равны 0.
# %.2f форматирует вывод до двух десятичных знаков.
print(
 'Fraction of those who did not receive a card and had no expenditures: %.2f'
 % ((expenditures_noncardholders == 0).mean()))
print()

# Выводим долю тех, кто получил карту и не сделал никаких расходов.
# (expenditures_cardholders == 0) — это булевый массив, где True для тех,
# у кого расходы равны 0.
# .mean() аналогично вычисляет среднее значение булевого массива,
# чтобы найти долю тех, кто не сделал расходов (расходы равны 0).
# %.2f форматирует вывод до двух десятичных знаков.
print(
    'Fraction of those who received a card and had no expenditures: %.2f'
    % ((expenditures_cardholders == 0).mean()))
print()

# Удаление утечек данных (leaky predictors) из набора данных.
# "Leaky predictors" — это признаки, которые могут содержать информацию,
# недоступную модели на момент предсказания,
# или напрямую связаны с целевой переменной.
# Например, переменная "expenditure" (расходы)
# может быть зависимой от наличия карты,
# и использование таких переменных может
# искусственно улучшить результаты модели.
# potential_leaks — список потенциально проблемных признаков,
# которые могут содержать "утечки".
potential_leaks = ['expenditure', 'share', 'active', 'majorcards']

# Удаляем эти признаки из набора данных X с помощью метода .drop().
# axis=1 означает, что удаляются столбцы (признаки), а не строки.
X2 = X.drop(potential_leaks, axis=1)

# Оценка модели после удаления "утекающих" признаков.
# Мы снова используем cross_val_score для выполнения кросс-валидации.
# my_pipeline — это конвейер с моделью (например, случайный лес),
# X2 — это набор признаков без потенциальных утечек, y — целевая переменная.
# cv=5 означает, что используется 5-кратная кросс-валидация.
# scoring='accuracy' указывает, что метрика для оценки — это точность.
cv_scores = cross_val_score(
    my_pipeline, X2, y,
    cv=5,  # 5-кратная кросс-валидация
    scoring='accuracy')  # Метрика — точность (accuracy)

# Выводим среднее значение точности
# после кросс-валидации с удалёнными утечками.
# cv_scores.mean() вычисляет среднее значение точности по всем 5 фолдам.
print("Cross-val accuracy: %f" % cv_scores.mean())
